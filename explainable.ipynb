{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تفسیر و توضیح مدل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tf-explain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/flowers'\n",
    "img = tf.keras.preprocessing.image.load_img('../data/flowers/daisy/100080576_f52e8ee070_n.jpg', target_size=(150, 150))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "data = img.reshape(1,*img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2162 images belonging to 5 classes.\n",
      "Found 2161 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "img_gen_train = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.5)\n",
    "\n",
    "train_data = img_gen_train.flow_from_directory('../data/flowers',\n",
    "                          batch_size = 8,\n",
    "                                  seed =42,\n",
    "                                  target_size = (150,150),\n",
    "                        subset = 'training' \n",
    "                                 )\n",
    "\n",
    "val_data = img_gen_train.flow_from_directory('../data/flowers',\n",
    "                          batch_size = 8,\n",
    "                                  seed =42,\n",
    "                                  target_size = (150,150),\n",
    "                                subset = 'validation' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "(5,)\n",
      "0\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "3\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "2\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "0\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "3\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "2\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "3\n",
      "(150, 150, 3)\n",
      "(5,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "(x,y) = val_data.next()\n",
    "(x,y) = val_data.next()\n",
    "for el, label in zip(x,y):\n",
    "    print(el.shape)\n",
    "    print(label.shape)\n",
    "    print(np.argmax(label))\n",
    "\n",
    "validation_class_zero = (np.array([\n",
    "    el for el, label in zip(x,y)\n",
    "    if np.all(np.argmax(label) == 0)\n",
    "][0:5]), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.29803923, 0.09803922, 0.        ],\n",
       "          [0.36862746, 0.13333334, 0.        ],\n",
       "          [0.42352945, 0.15294118, 0.        ],\n",
       "          ...,\n",
       "          [0.02745098, 0.05490196, 0.08627451],\n",
       "          [0.04705883, 0.0627451 , 0.10980393],\n",
       "          [0.10980393, 0.10196079, 0.18431373]],\n",
       " \n",
       "         [[0.31764707, 0.10588236, 0.        ],\n",
       "          [0.3803922 , 0.14509805, 0.00392157],\n",
       "          [0.43529415, 0.16470589, 0.00392157],\n",
       "          ...,\n",
       "          [0.0509804 , 0.07058824, 0.09411766],\n",
       "          [0.05882353, 0.06666667, 0.11764707],\n",
       "          [0.1137255 , 0.10588236, 0.18823531]],\n",
       " \n",
       "         [[0.36078432, 0.1254902 , 0.        ],\n",
       "          [0.43137258, 0.16862746, 0.00392157],\n",
       "          [0.4784314 , 0.18823531, 0.        ],\n",
       "          ...,\n",
       "          [0.16862746, 0.14509805, 0.18431373],\n",
       "          [0.1137255 , 0.10196079, 0.14509805],\n",
       "          [0.12156864, 0.10588236, 0.16470589]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6901961 , 0.52156866, 0.5568628 ],\n",
       "          [0.6901961 , 0.52156866, 0.54901963],\n",
       "          [0.69411767, 0.5176471 , 0.5294118 ],\n",
       "          ...,\n",
       "          [0.4784314 , 0.4156863 , 0.56078434],\n",
       "          [0.40784317, 0.40784317, 0.65882355],\n",
       "          [0.43137258, 0.44705886, 0.73333335]],\n",
       " \n",
       "         [[0.69803923, 0.5372549 , 0.5294118 ],\n",
       "          [0.69803923, 0.5372549 , 0.5294118 ],\n",
       "          [0.70980394, 0.5372549 , 0.5254902 ],\n",
       "          ...,\n",
       "          [0.3137255 , 0.3019608 , 0.5254902 ],\n",
       "          [0.37254903, 0.3803922 , 0.47058827],\n",
       "          [0.35686275, 0.34901962, 0.49411768]],\n",
       " \n",
       "         [[0.69803923, 0.5411765 , 0.50980395],\n",
       "          [0.70980394, 0.5411765 , 0.5137255 ],\n",
       "          [0.7137255 , 0.54509807, 0.5176471 ],\n",
       "          ...,\n",
       "          [0.34117648, 0.32941177, 0.60784316],\n",
       "          [0.35686275, 0.36862746, 0.43529415],\n",
       "          [0.2784314 , 0.28627452, 0.28235295]]],\n",
       " \n",
       " \n",
       "        [[[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]]]], dtype=float32), None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_class_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.callbacks import ActivationsVisualizationCallback\n",
    "import tf_explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ActivationsVisualizationCallback(\n",
    "        validation_data= (x,y),\n",
    "        layers_name=[\"activation_1\"],\n",
    "        output_dir='imgs/',\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNet( weights= 'imagenet',\n",
    "                                         input_shape = (150,150,3),\n",
    "                                         include_top = False)\n",
    "def create_transfer_learning_model():\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.layers.Input(shape = (150,150,3))\n",
    "    x = base_model(inputs,training = False)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(128,activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    outputs = keras.layers.Dense(5,activation='softmax' )(x)\n",
    "    final_model = keras.Model(inputs,outputs)\n",
    "    return final_model\n",
    "\n",
    "\n",
    "model = create_transfer_learning_model()\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss ='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/271 [==============================] - 30s 109ms/step - loss: 0.2616 - accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x156f4358d48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,epochs=1,\n",
    "          callbacks=[tf_explain.callbacks.VanillaGradientsCallback(validation_class_zero, class_index=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### روش smooth-grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y)  = val_date.next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-3e5d22dfe000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Start explainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m281\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 281 is the tabby cat index in ImageNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"grad_cam.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tf_explain\\core\\grad_cam.py\u001b[0m in \u001b[0;36mexplain\u001b[1;34m(self, validation_data, model, class_index, layer_name, colormap, image_weight)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         outputs, guided_grads = GradCAM.get_gradients_and_filters(\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         )\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "# Load a sample image (or multiple ones)\n",
    "img = tf.keras.preprocessing.image.load_img('imgs/cat.jpg', target_size=(224, 224))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "data = ([img], None)\n",
    "\n",
    "# Start explainer\n",
    "explainer = GradCAM()\n",
    "grid = explainer.explain(data, model, class_index=281)  # 281 is the tabby cat index in ImageNet\n",
    "\n",
    "explainer.save(grid, \".\", \"grad_cam.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[242., 237., 255.],\n",
       "        [225., 222., 243.],\n",
       "        [195., 194., 212.],\n",
       "        ...,\n",
       "        [232., 232., 234.],\n",
       "        [232., 232., 234.],\n",
       "        [232., 232., 234.]],\n",
       "\n",
       "       [[242., 237., 255.],\n",
       "        [223., 220., 241.],\n",
       "        [193., 192., 210.],\n",
       "        ...,\n",
       "        [232., 232., 234.],\n",
       "        [232., 232., 234.],\n",
       "        [232., 232., 234.]],\n",
       "\n",
       "       [[241., 236., 255.],\n",
       "        [221., 218., 239.],\n",
       "        [190., 189., 207.],\n",
       "        ...,\n",
       "        [232., 232., 234.],\n",
       "        [232., 232., 234.],\n",
       "        [232., 232., 234.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[122., 124., 123.],\n",
       "        [122., 124., 123.],\n",
       "        [122., 124., 123.],\n",
       "        ...,\n",
       "        [211., 211., 211.],\n",
       "        [211., 211., 211.],\n",
       "        [211., 211., 211.]],\n",
       "\n",
       "       [[119., 121., 120.],\n",
       "        [119., 121., 120.],\n",
       "        [119., 121., 120.],\n",
       "        ...,\n",
       "        [211., 211., 211.],\n",
       "        [211., 211., 211.],\n",
       "        [211., 211., 211.]],\n",
       "\n",
       "       [[121., 123., 122.],\n",
       "        [121., 123., 122.],\n",
       "        [121., 123., 122.],\n",
       "        ...,\n",
       "        [211., 211., 211.],\n",
       "        [211., 211., 211.],\n",
       "        [211., 211., 211.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "    img = tf.keras.preprocessing.image.load_img('imgs/cat.jpg', target_size=(224, 224))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    model.summary()\n",
    "    data = ([img], None)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tabby_cat_class_index = 281\n",
    "    explainer = SmoothGrad()\n",
    "    # Compute SmoothGrad on VGG16\n",
    "    grid = explainer.explain(data, model, tabby_cat_class_index, 20, 1.0)\n",
    "    explainer.save(grid, \".\", \"smoothgrad.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/271 [==============================] - 20s 75ms/step - loss: 1.3295 - accuracy: 0.7169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f086c5108>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,batch_size=16, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_date.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img('../data/flowers/daisy/100080576_f52e8ee070_n.jpg', target_size=(150, 150))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "data = ([img], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabby_cat_class_index = 0\n",
    "explainer = SmoothGrad()\n",
    "# Compute SmoothGrad on VGG16\n",
    "grid = explainer.explain(data, model, tabby_cat_class_index)\n",
    "explainer.save(grid, \".\", \"smoothgrad.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
